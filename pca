import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Sample dataset (you can replace this with your dataset)
# Let's say we have 5 samples and 3 features
data = np.array([
    [2.5, 2.4, 1.2],
    [0.5, 0.7, 0.3],
    [2.2, 2.9, 1.8],
    [1.9, 2.2, 1.5],
    [3.1, 3.0, 2.0]
])

# Step 1: Standardize the data
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# Step 2: Compute the covariance matrix
covariance_matrix = np.cov(scaled_data, rowvar=False)

# Step 3: Compute eigenvalues and eigenvectors
eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)

# Step 4: Sort eigenvalues and corresponding eigenvectors
sorted_indices = np.argsort(eigenvalues)[::-1]
sorted_eigenvectors = eigenvectors[:, sorted_indices]

# Step 5: Select the top 'k' eigenvectors (for 2 components)
n_components = 2
selected_eigenvectors = sorted_eigenvectors[:, :n_components]

# Step 6: Project the data onto the new feature space
pca_data_manual = np.dot(scaled_data, selected_eigenvectors)

# Step 7: Perform PCA using Scikit-Learn
pca = PCA(n_components=n_components)
pca_data_sklearn = pca.fit_transform(scaled_data)

# Step 8: Plot the results
plt.figure(figsize=(10, 5))

# Manual PCA
plt.subplot(1, 2, 1)
plt.scatter(pca_data_manual[:, 0], pca_data_manual[:, 1], color='r')
plt.title('PCA (Manual Implementation)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')

# PCA using Scikit-Learn
plt.subplot(1, 2, 2)
plt.scatter(pca_data_sklearn[:, 0], pca_data_sklearn[:, 1], color='b')
plt.title('PCA (Scikit-Learn Implementation)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()
